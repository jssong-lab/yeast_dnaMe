{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apps/software/Python/3.6.1-IGB-gcc-4.9.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Concatenate,Input, concatenate, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import multi_gpu_model\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obejctive write (network_input, network) pairs for SA\n",
    "Inputs should:\n",
    " + be contained in test set\n",
    " + be evenly distributed between high and low predicted ME inputs for networks trained on each conditions\n",
    " \n",
    "Output format:\n",
    " + for High methylation: 6 dataFrames, 1 for each conditions with\n",
    " \n",
    "| idx                        | p_pred | n_ume | m_me |\n",
    "| ---                        | ----- | ----- | ----- |\n",
    "| index in lists of input_output.pk  |   0.5  |  5      |   4   |\n",
    " + Similar for low methylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "### Functions \n",
    "## Somang\n",
    "def log_lkh_loss(y_true, y_pred):\n",
    "    m = y_true[:,0]\n",
    "    m = K.reshape(m,(-1,1))\n",
    "    n = y_true[:,1]\n",
    "    n = K.reshape(n,(-1,1))\n",
    "    return -K.mean(m*K.log(y_pred)+n*K.log(1-y_pred),axis=-1)\n",
    "\n",
    "def loadModel(hdf5path):\n",
    "    maxlen=201\n",
    "    filter_N = 80\n",
    "    hd_layer_N = 40\n",
    "    droprate2 = 0.2\n",
    "    droprate = 0.2\n",
    "    input_shape2 = (5,maxlen,1)\n",
    "\n",
    "    inp2 = Input(shape=input_shape2)\n",
    "    conv2 = Conv2D(filter_N,kernel_size=(5,6),strides=(4,1),activation='relu',padding='valid')(inp2)\n",
    "    pool2 = MaxPooling2D(pool_size=(1,7),padding='valid')(conv2)\n",
    "    drop2 = Dropout(droprate2)(pool2)\n",
    "    flt2 = Flatten()(drop2)\n",
    "    dns = Dense(hd_layer_N, activation='relu')(flt2)\n",
    "    drop = Dropout(droprate)(dns)\n",
    "    outp = Dense(1, activation='sigmoid')(drop)\n",
    "    model = Model(inputs=inp2,outputs=outp)\n",
    "\n",
    "    model.load_weights(hdf5path)\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=log_lkh_loss,optimizer=sgd)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## LOAD DATA \n",
    "os.chdir(\"../../forAlex_6conditions/\")  ## added by Alex \n",
    "data = pickle.load(open(\"./pkls/data_pred.pk\",\"rb\"))\n",
    "\n",
    "#input and outputs of NN\n",
    "#len(inout)=7\n",
    "#0:input, 1~6:outputs of each condition\n",
    "inout = pickle.load(open('./pkls/input_output.pk','rb'))\n",
    "\n",
    "#common indices for all 6 NN\n",
    "#len(test_lst)=7\n",
    "#0:input, 1~6:outputs of each condition\n",
    "[train_indx,vald_indx,test_indx] = pickle.load(open('./pkls/test0_indx0.pk','rb'))\n",
    "train_lst = [d[train_indx] for d in inout]\n",
    "vald_lst = [d[vald_indx] for d in inout]\n",
    "test_lst = [d[test_indx] for d in inout]\n",
    "\n",
    "#6 conditions and 6 hdf5s\n",
    "conditions = ['3A1', '3A13L', '3A2', '3A23L', '3B1', '3B13L-d1']\n",
    "hdf5s = [\"1110-0.8289-0.8272.hdf5\", \"451-1.6492-1.6407.hdf5\",\n",
    "         \"563-1.5381-1.5321.hdf5\", \"243-2.6437-2.6117.hdf5\", \n",
    "         \"391-0.5742-0.5694.hdf5\", \"1059-1.0502-1.0516.hdf5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "## Compile models\n",
    "models = []\n",
    "for cond , hdf5 in zip(conditions , hdf5s ):\n",
    "    models.append(loadModel(\"./weights/\"+cond+\"/\"+hdf5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Get highests pred_me inputs for each condiitions\n",
    "n_top = 50\n",
    "greatest = True\n",
    "outdir= \"/home/groups/song/songlab2/shared/Somang_Alex_share/interpret/MCMC/initializations\"\n",
    "os.makedirs(outdir, exist_ok = True)\n",
    "\n",
    "conditionDFs = { }  # conditionName : dataFrame \n",
    "for i, (model, cond) in enumerate(zip(models, conditions)):\n",
    "    preds_test = model.predict(test_lst[0],  )\n",
    "    if greatest:\n",
    "        tmp_sorted = np.argsort(preds_test.squeeze())[-1*(n_top):][::-1]\n",
    "    else:\n",
    "        tmp_sorted = np.argsort(preds_test.squeeze())[:n_top]\n",
    "    test_indx_sorted = np.array([ test_indx[i] for i in tmp_sorted ] )  # indices of inputs in each list of inout\n",
    "    out_true = test_lst[i+1][tmp_sorted ]   ## n_ume , n_me  for selected elements of inotu\n",
    "    \n",
    "    \n",
    "    conditionDF = pd.DataFrame(index = test_indx_sorted,\n",
    "                                data = np.concatenate([ np.asarray(preds_test[tmp_sorted]), out_true] ,axis = 1 ),\n",
    "                                columns = [\"p_pred\" , \"n_ume\" , \"n_me\"] )\n",
    "    conditionDFs[cond] = conditionDF\n",
    "    \n",
    "for cond , df in conditionDFs.items():\n",
    "    df.to_csv( os.path.join(outdir , \"{}_highest{}.tsv\".format(cond , n_top)), sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Get lowest pred_me inputs for each condiitions\n",
    "n_top = 50\n",
    "greatest = False\n",
    "outdir= \"/home/groups/song/songlab2/shared/Somang_Alex_share/interpret/MCMC/initializations\"\n",
    "os.makedirs(outdir, exist_ok = True)\n",
    "\n",
    "conditionDFs = { }  # conditionName : dataFrame \n",
    "for i, (model, cond) in enumerate(zip(models, conditions)):\n",
    "    preds_test = model.predict(test_lst[0],  )\n",
    "    if greatest:\n",
    "        tmp_sorted = np.argsort(preds_test.squeeze())[-1*(n_top)::][::-1]\n",
    "    else:\n",
    "        tmp_sorted = np.argsort(preds_test.squeeze())[ :n_top]\n",
    "    test_indx_sorted = np.array([ test_indx[i] for i in tmp_sorted ] )  # indices of inputs in each list of inout\n",
    "    out_true = test_lst[i+1][tmp_sorted ]   ## n_ume , n_me  for selected elements of inotu\n",
    "    \n",
    "    \n",
    "    conditionDF = pd.DataFrame(index = test_indx_sorted,\n",
    "                                data = np.concatenate([ np.asarray(preds_test[tmp_sorted]), out_true] ,axis = 1 ),\n",
    "                                columns = [\"p_pred\" , \"n_ume\" , \"n_me\"] )\n",
    "    conditionDFs[cond] = conditionDF\n",
    "    \n",
    "for cond , df in conditionDFs.items():\n",
    "    df.to_csv( os.path.join(outdir , \"{}_lowest{}.tsv\".format(cond , n_top)), sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
